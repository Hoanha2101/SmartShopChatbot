from langchain_core.messages import HumanMessage, SystemMessage, AIMessage, ToolMessage
from langchain.prompts import ChatPromptTemplate, HumanMessagePromptTemplate
from langchain_core.messages import ToolMessage
from langgraph.prebuilt import ToolNode
from langchain.tools import tool
from typing import TypedDict, List, Annotated
import operator
from IPython.display import Image, display
from langgraph.graph import StateGraph
import os
from ..models import llm
from ..Prompts import system_prompt

PROJECT_DIR = os.path.abspath(os.path.join(__file__, "..", "..", ".."))

class State(TypedDict):
    messages: Annotated[list, operator.add]

class ChatController:
    def __init__(self, llm, safe_tools, sensitive_tools, system_prompt, len_summary = 8):
        self.len_summary = len_summary
        self.llm = llm
    
        self.safe_tools = safe_tools
        self.safe_tools_node = ToolNode(tools=self.safe_tools)
        self.safe_tool_names = {tool.name for tool in self.safe_tools}
        
        self.sensitive_tools = sensitive_tools
        self.sensitive_tools_node = ToolNode(tools=self.sensitive_tools)
        self.sensitive_tool_names = {tool.name for tool in self.sensitive_tools}
        
        self.all_tools = self.safe_tools + self.sensitive_tools
        self.llm_with_tools = llm.bind_tools(self.all_tools)
        
        self.system_prompt = system_prompt
        
        self.app = self.build_graph()
        
        self.state = {"messages": [SystemMessage(content=system_prompt)]}
        self.len_state = 0
        
        # L∆∞u tr·ªØ to√†n b·ªô l·ªãch s·ª≠ chat (kh√¥ng b·ªã t√≥m t·∫Øt)
        self.full_chat_history = [SystemMessage(content=system_prompt)]
        
        # Prompt template cho t√≥m t·∫Øt
        self.summary_template = ChatPromptTemplate.from_messages([
            SystemMessage(content="""B·∫°n l√† m·ªôt AI chuy√™n t√≥m t·∫Øt cu·ªôc h·ªôi tho·∫°i. 
            Nhi·ªám v·ª• c·ªßa b·∫°n l√† t√≥m t·∫Øt l·∫°i nh·ªØng th√¥ng tin quan tr·ªçng t·ª´ cu·ªôc tr√≤ chuy·ªán d∆∞·ªõi ƒë√¢y.
            
            H√£y t√≥m t·∫Øt:
            1. Nh·ªØng ch·ªß ƒë·ªÅ ch√≠nh ƒë√£ ƒë∆∞·ª£c th·∫£o lu·∫≠n
            2. Th√¥ng tin quan tr·ªçng m√† ng∆∞·ªùi d√πng ƒë√£ cung c·∫•p
            3. C√°c y√™u c·∫ßu ho·∫∑c nhi·ªám v·ª• ƒë√£ ho√†n th√†nh
            4. Context quan tr·ªçng ƒë·ªÉ ti·∫øp t·ª•c cu·ªôc h·ªôi tho·∫°i
            
            Gi·ªØ l·∫°i nh·ªØng th√¥ng tin c√≥ th·ªÉ h·ªØu √≠ch cho c√°c t∆∞∆°ng t√°c ti·∫øp theo."""),
            HumanMessagePromptTemplate.from_template("H√£y t√≥m t·∫Øt cu·ªôc h·ªôi tho·∫°i sau:\n\n{conversation_history}")
        ])

    def llm_node(self, state: State):
        messages = state["messages"]
    
        # N·∫øu ch∆∞a c√≥ system message, th√™m v√†o
        if not messages or not isinstance(messages[0], SystemMessage):
            messages = [SystemMessage(content=self.system_prompt)] + messages
        
        response = self.llm_with_tools.invoke(messages)
        return {"messages": [response]}
    
    def route_from_llm(self, state: State):
        last_message = state["messages"][-1]
        # N·∫øu kh√¥ng c√≥ tool calls, k·∫øt th√∫c
        if not hasattr(last_message, "tool_calls") or not last_message.tool_calls:
            return "end"
        print(f"Tool list: {last_message.tool_calls}")
        # L·∫•y tool call ƒë·∫ßu ti√™n
        first_tool_call = last_message.tool_calls[0]
        tool_name = first_tool_call["name"]
        
        print(f"Tool ƒë∆∞·ª£c g·ªçi: {tool_name}")
        
        if tool_name in self.sensitive_tool_names:
            return "sensitive_confirm"
        elif tool_name in self.safe_tool_names:
            return "safe"
        else:
            return "end"
    
    def note_sensitive_confirm(self, state: State):
        last_message = state["messages"][-1]
        first_tool_call = last_message.tool_calls[0]
        tool_name = first_tool_call["name"]
        tool_args = first_tool_call["args"]
        print(f"‚ö†Ô∏è Tool nh·∫°y c·∫£m ƒë∆∞·ª£c g·ªçi: {tool_name} v·ªõi args {tool_args}")
        
        confirm = input(f"B·∫°n c√≥ ch·∫Øc ch·∫Øn mu·ªën s·ª≠ d·ª•ng tool nh·∫°y c·∫£m '{tool_name}' kh√¥ng? (y/n): ").strip().lower()
        
        if confirm == "y":
            # Th·ª±c thi tool nh·∫°y c·∫£m
            for tool in self.sensitive_tools:
                if tool.name == tool_name:
                    try:
                        tool_result = tool.invoke(tool_args)
                        return {"messages": [ToolMessage(content=str(tool_result), tool_call_id=first_tool_call["id"])]}
                    except Exception as e:
                        return {"messages": [ToolMessage(content=f"L·ªói khi ch·∫°y tool {tool_name}: {e}", tool_call_id=first_tool_call["id"])]}
        else:
            print("‚ùå Ng∆∞·ªùi d√πng ƒë√£ t·ª´ ch·ªëi ch·∫°y tool nh·∫°y c·∫£m.")
            # G·ª≠i ph·∫£n h·ªìi t·ª´ ch·ªëi v·ªÅ cho LLM ƒë·ªÉ x·ª≠ l√Ω ti·∫øp
            return {"messages": [AIMessage(content=f"Ng∆∞·ªùi d√πng ƒë√£ t·ª´ ch·ªëi s·ª≠ d·ª•ng tool nh·∫°y c·∫£m '{tool_name}'.")]}      
        
    def build_graph(self):
        workflow = StateGraph(State)
        
        # Add nodes
        workflow.add_node("llm", self.llm_node)
        workflow.add_node("safe_tools", self.safe_tools_node)
        workflow.add_node("sensitive_confirm", self.note_sensitive_confirm)
        
        # Add edges
        workflow.add_edge("__start__", "llm")
        workflow.add_conditional_edges(
            "llm",
            self.route_from_llm,
            {
                "safe": "safe_tools",
                "sensitive_confirm": "sensitive_confirm", 
                "end": "__end__"
            }
        )
        workflow.add_edge("safe_tools", "llm")
        workflow.add_edge("sensitive_confirm", "llm")
        
        return workflow.compile()
    
    def get_figure(self, path_plot=os.path.join(PROJECT_DIR, "illustration", "workflow.mmd")):
        graph = self.build_graph().get_graph()
        mermaid_syntax = graph.draw_mermaid()
        with open(path_plot, "w", encoding="utf-8") as f:
            f.write(mermaid_syntax)
        print(f"‚úÖ Mermaid source ƒë√£ ƒë∆∞·ª£c l∆∞u t·∫°i {path_plot} (m·ªü b·∫±ng VSCode ho·∫∑c mermaid viewer)")

    def _messages_to_string(self, messages: List):
        """Chuy·ªÉn ƒë·ªïi danh s√°ch messages th√†nh string ƒë·ªÉ t√≥m t·∫Øt"""
        conversation_text = ""
        for msg in messages:
            if isinstance(msg, SystemMessage):
                continue  # B·ªè qua system message
            elif isinstance(msg, HumanMessage):
                conversation_text += f"Human: {msg.content}\n"
            elif isinstance(msg, AIMessage):
                conversation_text += f"Assistant: {msg.content}\n"
            elif isinstance(msg, ToolMessage):
                conversation_text += f"Tool Result: {msg.content}\n"
        return conversation_text.strip()
    
    def _summarize_conversation(self, messages_to_summarize: List):
        """T√≥m t·∫Øt m·ªôt ph·∫ßn cu·ªôc h·ªôi tho·∫°i"""
        try:
            conversation_text = self._messages_to_string(messages_to_summarize)

            if not conversation_text:
                return "Kh√¥ng c√≥ n·ªôi dung ƒë·ªÉ t√≥m t·∫Øt."
            
            # T·∫°o prompt t√≥m t·∫Øt
            summary_prompt = self.summary_template.format_messages(
                conversation_history=conversation_text
            )

            # G·ªçi LLM ƒë·ªÉ t√≥m t·∫Øt
            summary_response = self.llm.invoke(summary_prompt)
            summary_content = summary_response.content if hasattr(summary_response, 'content') else str(summary_response)
            
            return summary_content
        
        except Exception as e:
            print(f"L·ªói khi t√≥m t·∫Øt: {e}")
            return "Kh√¥ng th·ªÉ t√≥m t·∫Øt cu·ªôc h·ªôi tho·∫°i do l·ªói h·ªá th·ªëng."

        
    def get_stats(self):
        """L·∫•y th·ªëng k√™ v·ªÅ cu·ªôc h·ªôi tho·∫°i"""
        current_count = len([msg for msg in self.state["messages"] if not isinstance(msg, SystemMessage)])
        full_count = len([msg for msg in self.full_chat_history if not isinstance(msg, SystemMessage)])
        
        return {
            "current_messages": current_count,
            "full_history_messages": full_count,
            "summary_threshold": self.len_summary,
            "has_summary": any("T√≥m t·∫Øt cu·ªôc h·ªôi tho·∫°i" in str(msg.content) for msg in self.state["messages"] if isinstance(msg, SystemMessage))
        }
    def _perform_summarization(self):
        """Th·ª±c hi·ªán t√≥m t·∫Øt khi c·∫ßn thi·∫øt"""
        try:
            # T√°ch system message v√† c√°c messages kh√°c
            system_msg = None
            other_messages = []
            
            for msg in self.state["messages"]:
                if isinstance(msg, SystemMessage):
                    system_msg = msg
                else:
                    other_messages.append(msg)
            
            if len(other_messages) < self.len_summary:
                return  # Kh√¥ng c·∫ßn t√≥m t·∫Øt
            
            # Gi·ªØ l·∫°i m·ªôt s·ªë messages g·∫ßn nh·∫•t, t√≥m t·∫Øt ph·∫ßn c√≤n l·∫°i
            messages_to_keep = 4  # Gi·ªØ l·∫°i 4 messages g·∫ßn nh·∫•t
            messages_to_summarize = other_messages[:-messages_to_keep] if len(other_messages) > messages_to_keep else other_messages[:-2]
            messages_to_keep_list = other_messages[-messages_to_keep:] if len(other_messages) > messages_to_keep else other_messages[-2:]
            
            # T√≥m t·∫Øt ph·∫ßn c≈©
            summary_content = self._summarize_conversation(messages_to_summarize)
                   
            # T·∫°o message t√≥m t·∫Øt
            summary_message = SystemMessage(
                content=f"[T√≥m t·∫Øt cu·ªôc h·ªôi tho·∫°i tr∆∞·ªõc ƒë√≥]: {summary_content}"
            )
            
            print("--------summary_message----------\n")
            print(summary_message)
            print("----------------------\n")
            
            # C·∫≠p nh·∫≠t state v·ªõi: system_prompt + summary + messages g·∫ßn nh·∫•t
            new_messages = [system_msg, summary_message] + messages_to_keep_list
            self.state["messages"] = new_messages
            
            print(f"‚úÖ ƒê√£ t√≥m t·∫Øt {len(messages_to_summarize)} messages th√†nh 1 summary message")
            print(f"üìä S·ªë messages hi·ªán t·∫°i: {len(self.state['messages'])}")
            
        except Exception as e:
            print(f"‚ùå L·ªói khi th·ª±c hi·ªán t√≥m t·∫Øt: {e}")
            
    def _should_summarize(self):
        """Ki·ªÉm tra xem c√≥ n√™n t√≥m t·∫Øt kh√¥ng"""
        # ƒê·∫øm s·ªë messages (tr·ª´ system message)
        message_count = len([msg for msg in self.state["messages"] if not isinstance(msg, SystemMessage)])
        return message_count >= self.len_summary
    
    def get_full_history(self):
        """L·∫•y to√†n b·ªô l·ªãch s·ª≠ chat (ch∆∞a t√≥m t·∫Øt)"""
        return self.full_chat_history
    
    def get_current_state(self):
        """L·∫•y state hi·ªán t·∫°i (ƒë√£ t√≥m t·∫Øt n·∫øu c·∫ßn)"""
        return self.state["messages"]
    
    def reset_conversation(self):
        """Reset cu·ªôc h·ªôi tho·∫°i"""
        self.state = {"messages": [SystemMessage(content=self.system_prompt)]}
        self.full_chat_history = [SystemMessage(content=self.system_prompt)]
        print("‚úÖ ƒê√£ reset cu·ªôc h·ªôi tho·∫°i")     
        
    def run(self, user_input: str):
        """Ch·∫°y workflow v·ªõi input t·ª´ ng∆∞·ªùi d√πng"""
        try:
            # Th√™m user message v√†o state
            user_message = HumanMessage(content=user_input)
            self.state["messages"].append(user_message)
            
            # L∆∞u v√†o full history
            self.full_chat_history.append(user_message)
            
            # Ch·∫°y workflow
            result = self.app.invoke(self.state, {"recursion_limit": 10})
            last_message = result["messages"][-1]
            
            if isinstance(last_message, AIMessage):
                bot_response = last_message.content
                
                # C·∫≠p nh·∫≠t state
                self.state = result
                
                # L∆∞u response v√†o full history
                self.full_chat_history.extend([msg for msg in result["messages"][1:] if ((msg not in self.full_chat_history) and (not isinstance(msg, SystemMessage)))])

                # Ki·ªÉm tra v√† th·ª±c hi·ªán t√≥m t·∫Øt n·∫øu c·∫ßn
                if self._should_summarize():
                    print("üîÑ ƒêang th·ª±c hi·ªán t√≥m t·∫Øt l·ªãch s·ª≠ chat...")
                    self._perform_summarization()
                
                return bot_response
            else:
                return "Xin l·ªói, t√¥i kh√¥ng th·ªÉ x·ª≠ l√Ω y√™u c·∫ßu n√†y."
        except Exception as e:
            print(f"‚ùå L·ªói trong qu√° tr√¨nh ch·∫°y: {e}")
            return f"Xin l·ªói, ƒë√£ x·∫£y ra l·ªói: {str(e)}"
        
