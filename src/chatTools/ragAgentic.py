import os
import chromadb
from chromadb.config import Settings
from langchain.text_splitter import RecursiveCharacterTextSplitter, CharacterTextSplitter
import shutil
from ..models import model_emb 

class RAG:
    _instance = None
    
    def __init__(self, 
                 base_db_folder: str = "database/rag",
                 db_name: str = "rag_db",
                 chroma_path: str = None,  # Máº·c Ä‘á»‹nh sáº½ tá»± Ä‘á»™ng táº¡o
                 
                 separator="\n",    
                 chunk_size=500,  
                 chunk_overlap=50, 
                 length_function=len
                 ):
        
        self.separator = separator
        self.chunk_size = chunk_size  
        self.chunk_overlap = chunk_overlap 
        self.length_function = length_function
        
        self.base_db_folder = base_db_folder
        self.db_name = db_name
        
        # Tá»± Ä‘á»™ng táº¡o Ä‘Æ°á»ng dáº«n náº¿u khÃ´ng Ä‘Æ°á»£c cung cáº¥p
        if chroma_path is None:
            self.chroma_path = os.path.join(os.getcwd(), "database", "chroma_db")
        else:
            self.chroma_path = chroma_path
            
        self.chunk_size = chunk_size
        self.chunk_overlap = chunk_overlap

        # Táº¡o thÆ° má»¥c náº¿u chÆ°a tá»“n táº¡i
        os.makedirs(self.chroma_path, exist_ok=True)
        
        # init chroma client
        self.client = chromadb.PersistentClient(path=self.chroma_path)
        self.collection = self.client.get_or_create_collection(name=self.db_name)
        
        print(f"ğŸ’¾ ChromaDB Ä‘Æ°á»£c lÆ°u táº¡i: {os.path.abspath(self.chroma_path)}")

    def load_file(self, file_path: str) -> str:
        """Äá»c toÃ n bá»™ file txt"""
        with open(file_path, "r", encoding="utf-8") as f:
            return f.read()

    def split_chunk(self, text: str):
        """Chia text thÃ nh chunks vá»›i RecursiveCharacterTextSplitter"""
        text_splitter = RecursiveCharacterTextSplitter(
            chunk_size=self.chunk_size,
            chunk_overlap=self.chunk_overlap,
            separators=["\n\n", "\n", " ", ""]
        )
        
        # text_splitter = CharacterTextSplitter(
        #     separator=self.separator,     
        #     chunk_size=self.chunk_size,   
        #     chunk_overlap=self.chunk_overlap,  
        #     length_function=self.length_function 
        # )
        
        chunks = text_splitter.split_text(text)
        return chunks

    def add_to_db(self, file_path: str):
        """Äá»c file, split chunk vÃ  add vÃ o ChromaDB"""
        text = self.load_file(file_path)
        chunks = self.split_chunk(text)

        file_name = os.path.basename(file_path)
        rel_path = os.path.relpath(file_path, os.path.dirname(file_path))
        file_prefix = file_name.replace('.', '_')

        for i, chunk in enumerate(chunks):
            emb = model_emb.encode(chunk).tolist()
            self.collection.add(
                documents=[chunk],
                embeddings=[emb],
                ids=[f"{file_prefix}_{i}"],
                metadatas=[{
                    'file_path': file_path,
                    'file_name': file_name,
                    'chunk_index': i,
                    'relative_path': rel_path
                }]
            )
        print(f"âœ… ÄÃ£ thÃªm {len(chunks)} chunks tá»« {file_path} vÃ o ChromaDB")


    def add_folder_to_db(self, folder_path: str, file_extensions: list = ['.txt', '.md', '.py', '.json']):
        """Äá»c táº¥t cáº£ files trong folder vÃ  add vÃ o ChromaDB"""
        if not os.path.exists(folder_path):
            print(f"âŒ Folder khÃ´ng tá»“n táº¡i: {folder_path}")
            return
        
        total_files = 0
        total_chunks = 0
        
        # Duyá»‡t qua táº¥t cáº£ files trong folder (bao gá»“m cáº£ subfolder)
        for root, dirs, files in os.walk(folder_path):
            for file in files:
                # Kiá»ƒm tra extension cá»§a file
                file_ext = os.path.splitext(file)[1].lower()
                if file_ext in file_extensions:
                    file_path = os.path.join(root, file)
                    
                    try:
                        # Äá»c vÃ  xá»­ lÃ½ file
                        text = self.load_file(file_path)
                        chunks = self.split_chunk(text)
                        
                        # Táº¡o relative path Ä‘á»ƒ lÃ m prefix cho ID
                        rel_path = os.path.relpath(file_path, folder_path)
                        file_prefix = rel_path.replace(os.sep, '_').replace('.', '_')
                        
                        # Add chunks vÃ o database
                        for i, chunk in enumerate(chunks):
                            emb = model_emb.encode(chunk).tolist()
                            self.collection.add(
                                documents=[chunk],
                                embeddings=[emb],
                                ids=[f"{file_prefix}_{i}"],
                                metadatas=[{
                                    'file_path': file_path,
                                    'file_name': file,
                                    'chunk_index': i,
                                    'relative_path': rel_path
                                }]
                            )
                        
                        total_files += 1
                        total_chunks += len(chunks)
                        print(f"âœ… ÄÃ£ xá»­ lÃ½: {rel_path} - {len(chunks)} chunks")
                        
                    except Exception as e:
                        print(f"âŒ Lá»—i khi xá»­ lÃ½ file {file_path}: {str(e)}")
                        continue
        
        print(f"ğŸ‰ HoÃ n thÃ nh! ÄÃ£ xá»­ lÃ½ {total_files} files vá»›i tá»•ng {total_chunks} chunks")

    def add_data(self, path: str, file_extensions: list = ['.txt', '.md', '.py', '.json']):
        """Method tá»•ng quÃ¡t Ä‘á»ƒ add file hoáº·c folder"""
        if os.path.isfile(path):
            # Náº¿u lÃ  file Ä‘Æ¡n
            self.add_to_db(path)
        elif os.path.isdir(path):
            # Náº¿u lÃ  folder
            self.add_folder_to_db(path, file_extensions)
        else:
            print(f"âŒ Path khÃ´ng há»£p lá»‡: {path}")

    def search(self, query: str, top_k: int = 3):
        """TÃ¬m kiáº¿m theo query"""
        q_emb = model_emb.encode(query).tolist()
        results = self.collection.query(
            query_embeddings=[q_emb],
            n_results=top_k,
            include=["embeddings", "documents", "metadatas", "distances"] # Máº·c Ä‘á»‹nh sáº½ ko láº¥y ra emb luÃ´n, pháº£i set thÃ¬ má»›i láº¥y ra.
        )
        
        return results["documents"]
    
    def search_with_neighbors(self, query: str, top_k: int = 3, return_docs_only: bool = True):
        """TÃ¬m kiáº¿m query, láº¥y thÃªm chunk trÆ°á»›c & sau má»—i káº¿t quáº£.
        Náº¿u return_docs_only=True thÃ¬ tráº£ ra list document thÃ´i."""
        q_emb = model_emb.encode(query).tolist()
        results = self.collection.query(
            query_embeddings=[q_emb],
            n_results=top_k,
            include=["documents", "metadatas", "distances"]
        )

        final_results = []

        for doc, meta in zip(results["documents"][0], results["metadatas"][0]):
            file_path = meta["file_path"]
            rel_path = meta["relative_path"]
            chunk_index = meta["chunk_index"]
            chunk_id = meta.get("chunk_id", f"{rel_path}_{chunk_index}")

            # láº¥y toÃ n bá»™ chunks trong file nÃ y
            file_chunks = self.collection.get(
                where={"relative_path": rel_path},
                include=["documents", "metadatas"]
            )

            # map index -> content
            chunks_map = {
                m["chunk_index"]: d
                for d, m in zip(file_chunks["documents"], file_chunks["metadatas"])
            }

            # láº¥y [index-1, index, index+1]
            neighbors = []
            for i in [chunk_index - 1, chunk_index, chunk_index + 1]:
                if i in chunks_map:
                    neighbors.append({
                        "chunk_index": i,
                        "document": chunks_map[i],
                        "file_path": file_path,
                        "relative_path": rel_path
                    })

            final_results.append({
                "match_id": chunk_id,
                "neighbors": neighbors
            })

        if return_docs_only:
            # gá»™p táº¥t cáº£ document láº¡i thÃ nh 1 list text
            docs = []
            for item in final_results:
                for n in item["neighbors"]:
                    docs.append(n["document"])
            return docs

        return final_results



    def search_with_metadata(self, query: str, top_k: int = 3):
        """TÃ¬m kiáº¿m kÃ¨m metadata Ä‘á»ƒ biáº¿t chunk tá»« file nÃ o"""
        q_emb = model_emb.encode(query).tolist()
        results = self.collection.query(
            query_embeddings=[q_emb],
            n_results=top_k
        )

        return {
            "documents": results["documents"][0],
            "metadatas": results["metadatas"][0],
            "ids": results["ids"][0],
            "distances": results["distances"][0]
        }
        
    # Tráº£ vá» cáº£ documents vÃ  metadata
    def get_db_info(self):
        """Hiá»ƒn thá»‹ thÃ´ng tin vá» database"""
        print(f"ğŸ“ Database path: {os.path.abspath(self.chroma_path)}")
        print(f"ğŸ“Š Database name: {self.db_name}")
        print(f"ğŸ“ Collections: {[col.name for col in self.client.list_collections()]}")
        print(f"ğŸ“ˆ Total documents: {self.collection.count()}")
        
        # Liá»‡t kÃª files trong database folder
        if os.path.exists(self.chroma_path):
            files = os.listdir(self.chroma_path)
            print(f"ğŸ“‚ Files in database folder: {files}")
        
        return {
            'path': os.path.abspath(self.chroma_path),
            'name': self.db_name,
            'collections': [col.name for col in self.client.list_collections()],
            'document_count': self.collection.count()
        }
    
    def clear_database(self):
        """XÃ³a toÃ n bá»™ database (collection + file lÆ°u trá»¯)"""
        try:
            # XÃ³a collection trong client
            self.client.delete_collection(self.db_name)
            print(f"ğŸ—‘ï¸ ÄÃ£ xÃ³a collection '{self.db_name}' trong client")

            # XÃ³a thÆ° má»¥c váº­t lÃ½ chá»©a DB
            if os.path.exists(self.chroma_path):
                shutil.rmtree(self.chroma_path)
                print(f"ğŸ—‘ï¸ ÄÃ£ xÃ³a toÃ n bá»™ database folder: {self.chroma_path}")

            # Táº¡o láº¡i thÆ° má»¥c rá»—ng Ä‘á»ƒ dÃ¹ng tiáº¿p
            os.makedirs(self.chroma_path, exist_ok=True)
            self.client = chromadb.PersistentClient(path=self.chroma_path)
            self.collection = self.client.get_or_create_collection(name=self.db_name)
            print("âœ… Database Ä‘Ã£ Ä‘Æ°á»£c reset má»›i hoÃ n toÃ n")

        except Exception as e:
            print(f"âŒ Lá»—i khi xÃ³a database: {e}")
        
    @classmethod
    def get_instance(cls):
        if cls._instance is None:
            cls._instance = cls()
        return cls._instance